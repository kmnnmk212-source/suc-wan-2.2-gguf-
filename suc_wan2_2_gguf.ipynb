{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSRQOCUR7MBM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (1) Install ComfyUI + dependencies\n",
        "!nvidia-smi\n",
        "\n",
        "# System deps\n",
        "!apt -y update\n",
        "!apt -y install -qq aria2 git wget\n",
        "\n",
        "# Clone ComfyUI\n",
        "%cd /content\n",
        "!git clone https://github.com/comfyanonymous/ComfyUI.git\n",
        "\n",
        "# Install ComfyUI requirements\n",
        "%cd /content/ComfyUI\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# Install ComfyUI-GGUF (for loading GGUF models)\n",
        "%cd /content/ComfyUI/custom_nodes\n",
        "!git clone https://github.com/city96/ComfyUI-GGUF.git\n",
        "\n",
        "# Optional: Wan helper nodes (quality-of-life)\n",
        "!git clone https://github.com/Kijai/ComfyUI-WanVideoWrapper.git\n",
        "\n",
        "# Create model folders\n",
        "%cd /content/ComfyUI\n",
        "!mkdir -p models/unet models/vae models/text_encoders models/clip_vision models/diffusion_models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ScWfrkKKpxZ",
        "outputId": "5b4e5ac6-bce1-4a7c-e8de-9610e58d261c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 14 03:02:15 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [88.8 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,581 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,627 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,623 kB]\n",
            "Get:16 https://cli.github.com/packages stable/main amd64 Packages [346 B]\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,006 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,274 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,267 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,310 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,797 kB]\n",
            "Fetched 30.0 MB in 5s (6,204 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "49 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 126374 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/content\n",
            "Cloning into 'ComfyUI'...\n",
            "remote: Enumerating objects: 24242, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 24242 (delta 71), reused 31 (delta 30), pack-reused 24144 (from 3)\u001b[K\n",
            "Receiving objects: 100% (24242/24242), 72.80 MiB | 20.82 MiB/s, done.\n",
            "Resolving deltas: 100% (16287/16287), done.\n",
            "/content/ComfyUI\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/content/ComfyUI/custom_nodes\n",
            "Cloning into 'ComfyUI-GGUF'...\n",
            "remote: Enumerating objects: 699, done.\u001b[K\n",
            "remote: Counting objects: 100% (351/351), done.\u001b[K\n",
            "remote: Compressing objects: 100% (160/160), done.\u001b[K\n",
            "remote: Total 699 (delta 313), reused 196 (delta 191), pack-reused 348 (from 2)\u001b[K\n",
            "Receiving objects: 100% (699/699), 193.75 KiB | 6.68 MiB/s, done.\n",
            "Resolving deltas: 100% (455/455), done.\n",
            "Cloning into 'ComfyUI-WanVideoWrapper'...\n",
            "remote: Enumerating objects: 4670, done.\u001b[K\n",
            "remote: Counting objects: 100% (1864/1864), done.\u001b[K\n",
            "remote: Compressing objects: 100% (429/429), done.\u001b[K\n",
            "remote: Total 4670 (delta 1595), reused 1469 (delta 1435), pack-reused 2806 (from 3)\u001b[K\n",
            "Receiving objects: 100% (4670/4670), 32.06 MiB | 32.60 MiB/s, done.\n",
            "Resolving deltas: 100% (3153/3153), done.\n",
            "/content/ComfyUI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAE_URL=\"https://huggingface.co/QuantStack/Wan2.2-S2V-14B-GGUF/resolve/main/VAE/wan_2.1_vae.safetensors?download=true\"\n",
        "VAE_OUT=\"/content/ComfyUI/models/vae/wan_2.1_vae.safetensors\""
      ],
      "metadata": {
        "id": "NEkz26KQXg9s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (2) Download Wan 2.2 GGUF + VAE + text encoder\n",
        "%cd /content/ComfyUI\n",
        "\n",
        "# GGUF: اخترنا S2V 14B Q4_K_M كافتراضي (يمكن تغييره لاحقًا)\n",
        "GGUF_URL=\"https://huggingface.co/QuantStack/Wan2.2-S2V-14B-GGUF/resolve/main/Wan2.2-S2V-14B-Q2_K.gguf?download=true\"\n",
        "GGUF_OUT=\"/content/ComfyUI/models/unet/Wan2.2-S2V-14B-Q2_K.gguf\"\n",
        "\n",
        "# VAE لنسخة 14B (Wan 2.1 VAE)\n",
        "VAE_URL=\"https://huggingface.co/QuantStack/Wan2.2-S2V-14B-GGUF/resolve/main/VAE/wan_2.1_vae.safetensors?download=true\"\n",
        "VAE_OUT=\"/content/ComfyUI/models/vae/wan_2.1_vae.safetensors\"\n",
        "\n",
        "# Text Encoder: umt5-xxl (safetensors مُعاد التغليف لـ ComfyUI)\n",
        "UMT5_URL=\"https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors?download=true\"\n",
        "UMT5_OUT=\"/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors\"\n",
        "\n",
        "# Download files\n",
        "!aria2c -q -x 16 -s 16 -o \"{GGUF_OUT.split('/')[-1]}\" \"{GGUF_URL}\" -d \"/content/ComfyUI/models/unet\"\n",
        "!aria2c -q -x 16 -s 16 -o \"{VAE_OUT.split('/')[-1]}\" \"{VAE_URL}\" -d \"/content/ComfyUI/models/vae\"\n",
        "!aria2c -q -x 16 -s 16 -o \"{UMT5_OUT.split('/')[-1]}\" \"{UMT5_URL}\" -d \"/content/ComfyUI/models/text_encoders\"\n",
        "\n",
        "# Show files\n",
        "!echo \"== UNET (GGUF) ==\" && ls -lh /content/ComfyUI/models/unet\n",
        "!echo \"== VAE ==\" && ls -lh /content/ComfyUI/models/vae\n",
        "!echo \"== TEXT ENCODERS ==\" && ls -lh /content/ComfyUI/models/text_encoders\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-7_MgnpKr8n",
        "outputId": "b3523cdb-7c1c-47ef-82da-d252df4d39df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI\n",
            "== UNET (GGUF) ==\n",
            "total 8.9G\n",
            "-rw-r--r-- 1 root root    0 Sep 14 03:02 put_unet_files_here\n",
            "-rw-r--r-- 1 root root 8.9G Sep 14 03:04 Wan2.2-S2V-14B-Q2_K.gguf\n",
            "== VAE ==\n",
            "total 0\n",
            "-rw-r--r-- 1 root root 0 Sep 14 03:02 put_vae_here\n",
            "== TEXT ENCODERS ==\n",
            "total 6.3G\n",
            "-rw-r--r-- 1 root root    0 Sep 14 03:02 put_text_encoder_files_here\n",
            "-rw-r--r-- 1 root root 6.3G Sep 14 03:05 umt5_xxl_fp8_e4m3fn_scaled.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (3) Download a ready GGUF workflow (JSON)\n",
        "%cd /content/ComfyUI\n",
        "!mkdir -p /content/ComfyUI/workflows\n",
        "\n",
        "# ورِكفلو S2V GGUF من QuantStack\n",
        "!wget -q -O \"/content/ComfyUI/workflows/QuantStack_Wan2.2_S2V_GGUF.json\" \\\n",
        "  \"https://huggingface.co/QuantStack/Wan2.2-S2V-14B-GGUF/resolve/main/workflow/QuantStack%20-%20Wan2.2%20S2V%20(GGUF).json?download=true\"\n",
        "\n",
        "!ls -lh /content/ComfyUI/workflows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn2zcphgKt-P",
        "outputId": "6ebfdff9-60e1-47e6-dc08-2922dfce6828"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI\n",
            "total 24K\n",
            "-rw-r--r-- 1 root root 23K Sep 14 03:08 QuantStack_Wan2.2_S2V_GGUF.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (4) Launch ComfyUI + public URL\n",
        "import os, subprocess, sys, time, threading\n",
        "\n",
        "# Download cloudflared for tunneling\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n",
        "\n",
        "# Start ComfyUI\n",
        "def run_comfy():\n",
        "    cmd = [\"python\", \"main.py\", \"--listen\", \"0.0.0.0\", \"--port\", \"8188\"]\n",
        "    p = subprocess.Popen(cmd, cwd=\"/content/ComfyUI\", stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in p.stdout:\n",
        "        sys.stdout.write(line)\n",
        "\n",
        "threading.Thread(target=run_comfy, daemon=True).start()\n",
        "time.sleep(5)\n",
        "\n",
        "# Create public URL\n",
        "public_url = subprocess.check_output([\"/content/cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:8188\"], text=True)\n",
        "print(\"\\n====== Public URL ======\\n\")\n",
        "print(public_url)\n",
        "print(\"\\nOpen the URL above to access ComfyUI.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e1XbVXMzKva2",
        "outputId": "26fb27fe-dca3-4891-a381-570c75326e3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n",
            "Python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.59\n",
            "****** User settings have been changed to be stored on the server instead of browser storage. ******\n",
            "****** For multi-user setups add the --multi-user CLI argument to enable multiple user profiles. ******\n",
            "ComfyUI frontend version: 1.26.11\n",
            "[Prompt Server] web root: /usr/local/lib/python3.12/dist-packages/comfyui_frontend_package/static\n",
            "Warning: Could not load sageattention: No module named 'sageattention'\n",
            "sageattention package is not installed, sageattention will not be available\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/nodes.py\", line 2133, in load_custom_node\n",
            "    module_spec.loader.exec_module(module)\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper/__init__.py\", line 1, in <module>\n",
            "    from .nodes import NODE_CLASS_MAPPINGS, NODE_DISPLAY_NAME_MAPPINGS\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper/nodes.py\", line 12, in <module>\n",
            "    from .wanvideo.modules.model import rope_params\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper/wanvideo/modules/__init__.py\", line 2, in <module>\n",
            "    from .t5 import T5Decoder, T5Encoder, T5EncoderModel, T5Model\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper/wanvideo/modules/t5.py\", line 11, in <module>\n",
            "    from .tokenizers import HuggingfaceTokenizer\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper/wanvideo/modules/tokenizers.py\", line 5, in <module>\n",
            "    import ftfy\n",
            "ModuleNotFoundError: No module named 'ftfy'\n",
            "\n",
            "Cannot import /content/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper module for custom nodes: No module named 'ftfy'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/nodes.py\", line 2133, in load_custom_node\n",
            "    module_spec.loader.exec_module(module)\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/__init__.py\", line 7, in <module>\n",
            "    from .nodes import NODE_CLASS_MAPPINGS\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 15, in <module>\n",
            "    from .ops import GGMLOps, move_patch_to_device\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/ops.py\", line 2, in <module>\n",
            "    import gguf\n",
            "ModuleNotFoundError: No module named 'gguf'\n",
            "\n",
            "Cannot import /content/ComfyUI/custom_nodes/ComfyUI-GGUF module for custom nodes: No module named 'gguf'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds (IMPORT FAILED): /content/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "   2.0 seconds (IMPORT FAILED): /content/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper\n",
            "\n",
            "Context impl SQLiteImpl.\n",
            "Will assume non-transactional DDL.\n",
            "No target revision found.\n",
            "Starting server\n",
            "\n",
            "To see the GUI go to: http://0.0.0.0:8188\n",
            "\n",
            "Stopped server\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1640356028.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Create public URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/content/cloudflared\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tunnel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--url\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"http://127.0.0.1:8188\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n====== Public URL ======\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    467\u001b[0m                **kwargs).stdout\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy gguf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndp5liboM-UR",
        "outputId": "cf9b7b14-b878-4907-bfd4-6ecb95404579"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting gguf\n",
            "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from gguf) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from gguf) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from gguf) (4.67.1)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gguf, ftfy\n",
            "Successfully installed ftfy-6.3.1 gguf-0.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت cloudflared\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n",
        "\n",
        "# تشغيل ComfyUI في الخلفية\n",
        "import subprocess, threading, time, sys\n",
        "\n",
        "def run_comfy():\n",
        "    cmd = [\"python\", \"main.py\", \"--listen\", \"0.0.0.0\", \"--port\", \"8188\"]\n",
        "    p = subprocess.Popen(cmd, cwd=\"/content/ComfyUI\", stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in p.stdout:\n",
        "        sys.stdout.write(line)\n",
        "\n",
        "threading.Thread(target=run_comfy, daemon=True).start()\n",
        "time.sleep(5)\n",
        "\n",
        "# إنشاء رابط عام\n",
        "public_url = subprocess.check_output([\"/content/cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:8188\"], text=True)\n",
        "print(public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0crId93uM--A",
        "outputId": "968bc1e2-5ef5-4b84-d3d3-2e7882d64fe4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n",
            "Python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.59\n",
            "ComfyUI frontend version: 1.26.11\n",
            "[Prompt Server] web root: /usr/local/lib/python3.12/dist-packages/comfyui_frontend_package/static\n",
            "Warning: Could not load sageattention: No module named 'sageattention'\n",
            "sageattention package is not installed, sageattention will not be available\n",
            "NumExpr defaulting to 2 threads.\n",
            "2025-09-14 03:10:59.306808: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757819459.556817    3571 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757819459.626447    3571 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757819460.144461    3571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757819460.144499    3571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757819460.144504    3571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757819460.144506    3571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-14 03:11:00.197142: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "ComfyUI-GGUF: Allowing full torch compile\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "  12.8 seconds: /content/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper\n",
            "\n",
            "Context impl SQLiteImpl.\n",
            "Will assume non-transactional DDL.\n",
            "No target revision found.\n",
            "Starting server\n",
            "\n",
            "To see the GUI go to: http://0.0.0.0:8188\n",
            "\n",
            "Stopped server\n",
            "FantasyPortrait nodes not available due to error in importing them: No module named 'onnx'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3276488224.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# إنشاء رابط عام\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/content/cloudflared\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tunnel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--url\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"http://127.0.0.1:8188\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    467\u001b[0m                **kwargs).stdout\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت cloudflared\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n",
        "\n",
        "# تشغيل ComfyUI في الخلفية\n",
        "import subprocess, threading, time, sys\n",
        "\n",
        "def run_comfy():\n",
        "    cmd = [\"python\", \"main.py\", \"--listen\", \"0.0.0.0\", \"--port\", \"8188\"]\n",
        "    p = subprocess.Popen(cmd, cwd=\"/content/ComfyUI\", stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in p.stdout:\n",
        "        sys.stdout.write(line)\n",
        "\n",
        "threading.Thread(target=run_comfy, daemon=True).start()\n",
        "time.sleep(5)\n",
        "\n",
        "# إنشاء رابط عام\n",
        "public_url = subprocess.check_output(\n",
        "    [\"/content/cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:8188\"],\n",
        "    text=True\n",
        ")\n",
        "print(\"\\n====== رابط ComfyUI العام ======\\n\")\n",
        "print(public_url)\n"
      ],
      "metadata": {
        "id": "SVwZmm3bNBqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت cloudflared\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n",
        "\n",
        "# إنشاء رابط عام للمنفذ 8188\n",
        "!./cloudflared tunnel --url http://127.0.0.1:8188 --no-autoupdate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvoJQHW7NmXK",
        "outputId": "aa46cf63-f8f4-498d-e951-a2af387acae6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./cloudflared: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n"
      ],
      "metadata": {
        "id": "gtfVDdomODdy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, threading, time, sys\n",
        "\n",
        "def run_comfy():\n",
        "    cmd = [\"python\", \"main.py\", \"--listen\", \"0.0.0.0\", \"--port\", \"8188\"]\n",
        "    p = subprocess.Popen(cmd, cwd=\"/content/ComfyUI\", stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in p.stdout:\n",
        "        sys.stdout.write(line)\n",
        "\n",
        "threading.Thread(target=run_comfy, daemon=True).start()\n",
        "time.sleep(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQA2U2ceOR04",
        "outputId": "238f3199-1ead-4603-8f93-c306f85e97e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/cloudflared tunnel --url http://127.0.0.1:8188 --no-autoupdate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIS-YJS_OUBg",
        "outputId": "82ef89fe-922a-4714-b01a-0dc1bc5de4ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-09-14T03:16:42Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-09-14T03:16:42Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m |  https://bold-destination-gmt-steering.trycloudflare.com                                   |\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.8.1 (Checksum a66353004197ee4c1fcb68549203824882bba62378ad4d00d234bdb8251f1114)\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://127.0.0.1:8188]\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 4e1dd6d7-1da1-4f5b-b8a9-38d48b8a9172\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43\n",
            "2025/09/14 03:16:46 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-09-14T03:16:46Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m33f9cb9d-4ed3-4981-ab3e-9d3d122fabe1 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43 \u001b[36mlocation=\u001b[0mams06 \u001b[36mprotocol=\u001b[0mquic\n",
            "got prompt\n",
            "invalid prompt: {'type': 'invalid_prompt', 'message': 'Cannot execute because a node is missing the class_type property.', 'details': \"Node ID '#67'\", 'extra_info': {}}\n",
            "got prompt\n",
            "invalid prompt: {'type': 'invalid_prompt', 'message': 'Cannot execute because a node is missing the class_type property.', 'details': \"Node ID '#67'\", 'extra_info': {}}\n",
            "got prompt\n",
            "invalid prompt: {'type': 'invalid_prompt', 'message': 'Cannot execute because a node is missing the class_type property.', 'details': \"Node ID '#67'\", 'extra_info': {}}\n",
            "got prompt\n",
            "invalid prompt: {'type': 'invalid_prompt', 'message': 'Cannot execute because a node is missing the class_type property.', 'details': \"Node ID '#67'\", 'extra_info': {}}\n",
            "got prompt\n",
            "invalid prompt: {'type': 'invalid_prompt', 'message': 'Cannot execute because a node is missing the class_type property.', 'details': \"Node ID '#67'\", 'extra_info': {}}\n",
            "\n",
            "Stopped server\n",
            "FantasyPortrait nodes not available due to error in importing them: No module named 'onnx'\n",
            "\u001b[90m2025-09-14T03:32:26Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-09-14T03:32:27Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43\n",
            "\u001b[90m2025-09-14T03:32:27Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43\n",
            "\u001b[90m2025-09-14T03:32:27Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43\n",
            "\u001b[90m2025-09-14T03:32:27Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43\n",
            "\u001b[90m2025-09-14T03:32:27Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2025-09-14T03:32:27Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-09-14T03:32:27Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-09-14T03:32:27Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ComfyUI/custom_nodes\n",
        "!git clone https://github.com/ltdrdata/ComfyUI-Image-Resize.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1fXhhlIOXko",
        "outputId": "f8e3ab9f-f01e-4263-e35e-0eee3f2b1110"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI/custom_nodes\n",
            "Cloning into 'ComfyUI-Image-Resize'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pythongosssss/ComfyUI-Custom-Scripts.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzfrwpl6SBQy",
        "outputId": "98c04010-7247-41fb-f4e7-95e97323d607"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ComfyUI-Custom-Scripts'...\n",
            "remote: Enumerating objects: 2334, done.\u001b[K\n",
            "remote: Counting objects: 100% (964/964), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 2334 (delta 887), reused 819 (delta 819), pack-reused 1370 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2334/2334), 526.91 KiB | 11.97 MiB/s, done.\n",
            "Resolving deltas: 100% (1400/1400), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pp4QKhr0SRjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8hthW5UvSW_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, threading, time, sys\n",
        "\n",
        "def run_comfy():\n",
        "    cmd = [\"python\", \"main.py\", \"--listen\", \"0.0.0.0\", \"--port\", \"8188\"]\n",
        "    p = subprocess.Popen(cmd, cwd=\"/content/ComfyUI\", stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in p.stdout:\n",
        "        sys.stdout.write(line)\n",
        "\n",
        "threading.Thread(target=run_comfy, daemon=True).start()\n",
        "time.sleep(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f6f52e-90ea-4333-d672-e511306bb8fc",
        "id": "LQ2JhM4zSXQs"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/cloudflared tunnel --url http://127.0.0.1:8188 --no-autoupdate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03bb34b6-95d7-4a43-aa71-6491b693e9f8",
        "id": "yHbzluFESXQu"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-09-14T03:34:17Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-09-14T03:34:17Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "Warning: Could not load sageattention: No module named 'sageattention'\n",
            "sageattention package is not installed, sageattention will not be available\n",
            "NumExpr defaulting to 2 threads.\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m |  https://hospitals-generated-damage-arctic.trycloudflare.com                               |\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.8.1 (Checksum a66353004197ee4c1fcb68549203824882bba62378ad4d00d234bdb8251f1114)\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://127.0.0.1:8188]\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: d0ea458e-5923-4886-bd85-c2c8121e4247\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.57\n",
            "2025/09/14 03:34:21 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-09-14T03:34:21Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0ma5951390-ebf6-4eeb-ad46-604713a275de \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.57 \u001b[36mlocation=\u001b[0mams07 \u001b[36mprotocol=\u001b[0mquic\n",
            "2025-09-14 03:34:22.134427: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757820862.154248    9443 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757820862.160224    9443 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757820862.175456    9443 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757820862.175480    9443 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757820862.175483    9443 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757820862.175485    9443 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-14 03:34:22.180111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "ComfyUI-GGUF: Allowing full torch compile\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "   0.2 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Custom-Scripts\n",
            "   6.9 seconds: /content/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper\n",
            "\n",
            "Context impl SQLiteImpl.\n",
            "Will assume non-transactional DDL.\n",
            "No target revision found.\n",
            "Starting server\n",
            "\n",
            "To see the GUI go to: http://0.0.0.0:8188\n",
            "\u001b[90m2025-09-14T03:35:56Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 17 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://127.0.0.1:8188\n",
            "\u001b[90m2025-09-14T03:35:56Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 17 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://hospitals-generated-damage-arctic.trycloudflare.com/assets/index-Bd_Phb6O.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.57 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-09-14T03:37:36Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 49 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://127.0.0.1:8188\n",
            "\u001b[90m2025-09-14T03:37:36Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 49 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://hospitals-generated-damage-arctic.trycloudflare.com/assets/index-Bd_Phb6O.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.57 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-09-14T03:37:40Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 29 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://127.0.0.1:8188\n",
            "\u001b[90m2025-09-14T03:37:40Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 29 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://hospitals-generated-damage-arctic.trycloudflare.com/assets/index-Bd_Phb6O.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.57 \u001b[36mtype=\u001b[0mhttp\n",
            "\n",
            "Stopped server\n",
            "FantasyPortrait nodes not available due to error in importing them: No module named 'onnx'\n",
            "\u001b[90m2025-09-14T03:37:53Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-09-14T03:37:56Z\u001b[0m \u001b[32mINF\u001b[0m Unregistered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.57\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, threading, time, sys\n",
        "\n",
        "def run_comfy():\n",
        "    cmd = [\"python\", \"main.py\", \"--listen\", \"0.0.0.0\", \"--port\", \"8188\"]\n",
        "    p = subprocess.Popen(cmd, cwd=\"/content/ComfyUI\", stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in p.stdout:\n",
        "        sys.stdout.write(line)\n",
        "\n",
        "threading.Thread(target=run_comfy, daemon=True).start()\n",
        "time.sleep(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7-DFZHfSW8Z",
        "outputId": "d8cddbc6-e377-4d49-d761-fa518253b39f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تحميل cloudflared\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n",
        "\n",
        "# تشغيل النفق\n",
        "!/content/cloudflared tunnel --url http://127.0.0.1:8188 --no-autoupdate"
      ],
      "metadata": {
        "id": "r1plaAQ5TTuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, threading, time, sys\n",
        "\n",
        "def run_comfy():\n",
        "    cmd = [\"python\", \"main.py\", \"--listen\", \"0.0.0.0\", \"--port\", \"8188\"]\n",
        "    p = subprocess.Popen(cmd, cwd=\"/content/ComfyUI\", stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in p.stdout:\n",
        "        sys.stdout.write(line)\n",
        "\n",
        "threading.Thread(target=run_comfy, daemon=True).start()\n",
        "time.sleep(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD4lnfjdTWNR",
        "outputId": "087854d8-c743-4538-e198-385f7e2ec386"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n",
        "!/content/cloudflared tunnel --url http://127.0.0.1:8188 --no-autoupdate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su97GIbjT6tz",
        "outputId": "a872a1f5-ce25-4241-deff-879a2d457918"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-09-14T03:44:18Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-09-14T03:44:18Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "Warning: Could not load sageattention: No module named 'sageattention'\n",
            "sageattention package is not installed, sageattention will not be available\n",
            "NumExpr defaulting to 2 threads.\n",
            "2025-09-14 03:44:22.066109: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757821462.085861   12114 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757821462.091852   12114 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757821462.107056   12114 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757821462.107082   12114 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757821462.107085   12114 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757821462.107087   12114 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-14 03:44:22.111652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m |  https://glass-count-epic-timothy.trycloudflare.com                                        |\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.8.1 (Checksum a66353004197ee4c1fcb68549203824882bba62378ad4d00d234bdb8251f1114)\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://127.0.0.1:8188]\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 6e5abfc3-5d1b-4864-8cee-2a59cca741e9\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-09-14T03:44:22Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.13\n",
            "2025/09/14 03:44:22 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-09-14T03:44:23Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m3bbb0129-c690-4b37-972c-8be62946fa21 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.13 \u001b[36mlocation=\u001b[0mams20 \u001b[36mprotocol=\u001b[0mquic\n",
            "ComfyUI-GGUF: Allowing full torch compile\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Custom-Scripts\n",
            "   6.4 seconds: /content/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper\n",
            "\n",
            "Context impl SQLiteImpl.\n",
            "Will assume non-transactional DDL.\n",
            "No target revision found.\n",
            "Starting server\n",
            "\n",
            "To see the GUI go to: http://0.0.0.0:8188\n",
            "\n",
            "Stopped server\n",
            "FantasyPortrait nodes not available due to error in importing them: No module named 'onnx'\n",
            "\u001b[90m2025-09-14T03:44:47Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, threading, time, sys\n",
        "\n",
        "def run_comfy():\n",
        "    cmd = [\"python\", \"main.py\", \"--listen\", \"0.0.0.0\", \"--port\", \"8188\"]\n",
        "    p = subprocess.Popen(cmd, cwd=\"/content/ComfyUI\", stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in p.stdout:\n",
        "        sys.stdout.write(line)\n",
        "\n",
        "threading.Thread(target=run_comfy, daemon=True).start()\n",
        "time.sleep(8)  # ندي وقت كافي لبدء السيرفر\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K8rX2ewU2tC",
        "outputId": "d42f18e9-e84f-441c-d943-591f0d5dfcc8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n",
            "Python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.59\n",
            "ComfyUI frontend version: 1.26.11\n",
            "[Prompt Server] web root: /usr/local/lib/python3.12/dist-packages/comfyui_frontend_package/static\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n",
        "\n"
      ],
      "metadata": {
        "id": "uD73AuOzU3Iq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ComfyUI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8JdEWwrYJoL",
        "outputId": "8b2e72ef-917d-45ac-a45a-639b0bfe1dec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/cloudflared tunnel --url http://127.0.0.1:8188 --no-autoupdate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcMHpVFUU_Gy",
        "outputId": "becc4156-c2ec-4cc6-90c3-01da202016e3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-09-14T04:05:20Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-09-14T04:05:20Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m |  https://sci-characters-san-definitions.trycloudflare.com                                  |\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.8.1 (Checksum a66353004197ee4c1fcb68549203824882bba62378ad4d00d234bdb8251f1114)\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://127.0.0.1:8188]\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 3eca9bf7-ad57-41b3-85c6-ef7c4624bdda\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.227\n",
            "2025/09/14 04:05:25 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-09-14T04:05:25Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0mdb1b1dd8-578b-4ebc-8be0-0dfb4b1b2f09 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.227 \u001b[36mlocation=\u001b[0mams07 \u001b[36mprotocol=\u001b[0mquic\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Custom validation failed for node: audio - Invalid audio file: input_wan2.2_s2v.wav\n",
            "* UnetLoaderGGUF 61:\n",
            "  - Value not in list: unet_name: 'Qwen 2SV\\Wan2.2-S2V-14B-Q2_K.gguf' not in ['Wan2.2-S2V-14B-Q2_K.gguf']\n",
            "* AudioEncoderLoader 57:\n",
            "  - Value not in list: audio_encoder_name: 'wav2vec2_large_english.safetensors' not in []\n",
            "* LoadImage 52:\n",
            "  - Custom validation failed for node: image - Invalid image file: flux_dev_example.png\n",
            "* VAELoader 63:\n",
            "  - Value not in list: vae_name: 'Qwen2.1\\Wan2.1_VAE.safetensors' not in ['wan_2.1_vae.safetensors', 'pixel_space']\n",
            "* CLIPLoaderGGUF 62:\n",
            "  - Value not in list: clip_name: 'Wan\\umt5-xxl-encoder-Q4_K_S.gguf' not in ['umt5_xxl_fp8_e4m3fn_scaled.safetensors']\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 68:\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Custom validation failed for node: audio - Invalid audio file: input_wan2.2_s2v.wav\n",
            "* UnetLoaderGGUF 61:\n",
            "  - Value not in list: unet_name: 'Qwen 2SV\\Wan2.2-S2V-14B-Q2_K.gguf' not in ['Wan2.2-S2V-14B-Q2_K.gguf']\n",
            "* AudioEncoderLoader 57:\n",
            "  - Value not in list: audio_encoder_name: 'wav2vec2_large_english.safetensors' not in []\n",
            "* LoadImage 52:\n",
            "  - Custom validation failed for node: image - Invalid image file: flux_dev_example.png\n",
            "* CLIPLoaderGGUF 62:\n",
            "  - Value not in list: clip_name: 'Wan\\umt5-xxl-encoder-Q4_K_S.gguf' not in ['umt5_xxl_fp8_e4m3fn_scaled.safetensors']\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 68:\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Custom validation failed for node: audio - Invalid audio file: input_wan2.2_s2v.wav\n",
            "* AudioEncoderLoader 57:\n",
            "  - Value not in list: audio_encoder_name: 'wav2vec2_large_english.safetensors' not in []\n",
            "* LoadImage 52:\n",
            "  - Custom validation failed for node: image - Invalid image file: flux_dev_example.png\n",
            "* CLIPLoaderGGUF 62:\n",
            "  - Value not in list: clip_name: 'Wan\\umt5-xxl-encoder-Q4_K_S.gguf' not in ['umt5_xxl_fp8_e4m3fn_scaled.safetensors']\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 68:\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Custom validation failed for node: audio - Invalid audio file: input_wan2.2_s2v.wav\n",
            "* AudioEncoderLoader 57:\n",
            "  - Value not in list: audio_encoder_name: 'wav2vec2_large_english.safetensors' not in []\n",
            "* LoadImage 52:\n",
            "  - Custom validation failed for node: image - Invalid image file: flux_dev_example.png\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 68:\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Custom validation failed for node: audio - Invalid audio file: input_wan2.2_s2v.wav\n",
            "* AudioEncoderLoader 57:\n",
            "  - Value not in list: audio_encoder_name: 'wav2vec2_large_english.safetensors' not in []\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "WARNING: [Errno 2] No such file or directory: '/content/ComfyUI/input/input_wan2.2_s2v.wav'\n",
            "Prompt executed in 0.11 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Custom validation failed for node: audio - Invalid audio file: input_wan2.2_s2v.wav\n",
            "* AudioEncoderLoader 57:\n",
            "  - Value not in list: audio_encoder_name: 'wav2vec2_large_english.safetensors' not in []\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "WARNING: [Errno 2] No such file or directory: '/content/ComfyUI/input/input_wan2.2_s2v.wav'\n",
            "Prompt executed in 0.01 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Custom validation failed for node: audio - Invalid audio file: input_wan2.2_s2v.wav\n",
            "* AudioEncoderLoader 57:\n",
            "  - Value not in list: audio_encoder_name: 'wav2vec2_large_english.safetensors' not in []\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "WARNING: [Errno 2] No such file or directory: '/content/ComfyUI/input/input_wan2.2_s2v.wav'\n",
            "Prompt executed in 0.01 seconds\n",
            "\n",
            "Stopped server\n",
            "FantasyPortrait nodes not available due to error in importing them: No module named 'onnx'\n",
            "\u001b[90m2025-09-14T04:19:26Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ComfyUI/models/vae\n",
        "!wget https://huggingface.co/alliestar/wan22-comfyui-complete/resolve/main/vae/wan_2.1_vae.safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RJAA9AWU_Z5",
        "outputId": "5de030fb-f4de-4bf1-cb0a-378b89077fe7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI/models/vae\n",
            "--2025-09-14 03:58:53--  https://huggingface.co/alliestar/wan22-comfyui-complete/resolve/main/vae/wan_2.1_vae.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.49, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/66/62/6662d6e1ff58a547f072c3fa2f3a8b72b2f6106f012918d72b7ee2aa139e3826/2fc39d31359a4b0a64f55876d8ff7fa8d780956ae2cb13463b0223e15148976b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27wan_2.1_vae.safetensors%3B+filename%3D%22wan_2.1_vae.safetensors%22%3B&Expires=1757825933&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NzgyNTkzM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY2LzYyLzY2NjJkNmUxZmY1OGE1NDdmMDcyYzNmYTJmM2E4YjcyYjJmNjEwNmYwMTI5MThkNzJiN2VlMmFhMTM5ZTM4MjYvMmZjMzlkMzEzNTlhNGIwYTY0ZjU1ODc2ZDhmZjdmYThkNzgwOTU2YWUyY2IxMzQ2M2IwMjIzZTE1MTQ4OTc2Yj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=AgX4drOG7cQIEph-geAbYoiDVD7yVAILRC1w-Oz0%7EUvgZa6Mpywi9GiS%7EuR6FJkjHsfx51nMHMUooVYi-ONC4-bmWysBwoMUOccIvuRYKXhGGKIwv55h0M46ZsuqAiRyDQf8EMyAxTkLDiRKa2psQ-j6EFWbbkDLHVn05ah9UJvqnIyuGzo9klf0GJIz4G26XTlKZrxQthk2pTYMsnlvowuzRL3PwFysqUC3A5ZWLizZKwtQNb9axP%7EMAgN4ffAGgRFMITOdta84Fodi%7EY7fd-pkdVNWjmVy38nQxNn%7E9W-9XOVqN4UWyw6tYQ5Nm9MeRh0icBw3LGp46L1NJXcHRg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-09-14 03:58:53--  https://cdn-lfs-us-1.hf.co/repos/66/62/6662d6e1ff58a547f072c3fa2f3a8b72b2f6106f012918d72b7ee2aa139e3826/2fc39d31359a4b0a64f55876d8ff7fa8d780956ae2cb13463b0223e15148976b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27wan_2.1_vae.safetensors%3B+filename%3D%22wan_2.1_vae.safetensors%22%3B&Expires=1757825933&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NzgyNTkzM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY2LzYyLzY2NjJkNmUxZmY1OGE1NDdmMDcyYzNmYTJmM2E4YjcyYjJmNjEwNmYwMTI5MThkNzJiN2VlMmFhMTM5ZTM4MjYvMmZjMzlkMzEzNTlhNGIwYTY0ZjU1ODc2ZDhmZjdmYThkNzgwOTU2YWUyY2IxMzQ2M2IwMjIzZTE1MTQ4OTc2Yj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=AgX4drOG7cQIEph-geAbYoiDVD7yVAILRC1w-Oz0%7EUvgZa6Mpywi9GiS%7EuR6FJkjHsfx51nMHMUooVYi-ONC4-bmWysBwoMUOccIvuRYKXhGGKIwv55h0M46ZsuqAiRyDQf8EMyAxTkLDiRKa2psQ-j6EFWbbkDLHVn05ah9UJvqnIyuGzo9klf0GJIz4G26XTlKZrxQthk2pTYMsnlvowuzRL3PwFysqUC3A5ZWLizZKwtQNb9axP%7EMAgN4ffAGgRFMITOdta84Fodi%7EY7fd-pkdVNWjmVy38nQxNn%7E9W-9XOVqN4UWyw6tYQ5Nm9MeRh0icBw3LGp46L1NJXcHRg__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.239.69.53, 18.239.69.126, 18.239.69.55, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.239.69.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253815318 (242M) [binary/octet-stream]\n",
            "Saving to: ‘wan_2.1_vae.safetensors’\n",
            "\n",
            "wan_2.1_vae.safeten 100%[===================>] 242.06M  53.7MB/s    in 4.9s    \n",
            "\n",
            "2025-09-14 03:58:58 (49.2 MB/s) - ‘wan_2.1_vae.safetensors’ saved [253815318/253815318]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ComfyUI/custom_nodes\n",
        "\n",
        "!git clone https://github.com/palant/image-resize-comfyui"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrpvTCrrYCRS",
        "outputId": "b867c4ba-5273-4982-cf2b-68c0e998d3dc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI/custom_nodes\n",
            "Cloning into 'image-resize-comfyui'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 13 (delta 4), reused 9 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (13/13), 39.02 KiB | 2.29 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ComfyUI/models/audio_encoders\n",
        "\n",
        "!wget https://huggingface.co/Wan-AI/Wan2.2-S2V-14B/resolve/main/wav2vec2-large-xlsr-53-english/model.safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VzDVSG0ZY2b",
        "outputId": "3b8ce89f-e708-46b0-b7b2-dc0c10532309"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI/models/audio_encoders\n",
            "--2025-09-14 04:19:31--  https://huggingface.co/Wan-AI/Wan2.2-S2V-14B/resolve/main/wav2vec2-large-xlsr-53-english/model.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.16, 18.239.50.49, 18.239.50.80, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/68abccbf1935e46075b39df2/4be6804169c3353c147da4206c3982c1073abe8ac17f729a2a4c9126a8471e38?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250914%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250914T041931Z&X-Amz-Expires=3600&X-Amz-Signature=34291451127dd49a234bbe1cf841cce05475acaabeac0fbbc65cd7da3c874157&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&x-id=GetObject&Expires=1757827171&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NzgyNzE3MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OGFiY2NiZjE5MzVlNDYwNzViMzlkZjIvNGJlNjgwNDE2OWMzMzUzYzE0N2RhNDIwNmMzOTgyYzEwNzNhYmU4YWMxN2Y3MjlhMmE0YzkxMjZhODQ3MWUzOCoifV19&Signature=JYIRwDQZ49haJARFreNe%7EJ1Lx1BIUzOKy5plBHrt8Zd-1ITXhADJwvgJtn4vhSNp6fgIhGkPg2MLnsqImvrWhRkOTBvcBj3dDQP7mzc3Oh%7ElMlo56UmLB4BRC14Wxt75CwhCVOjclCv8J9vqec%7Er52xxefv-xxILboNIKQgJGHxEJBMbCpa%7EcttR4Z2-r%7E5GtI31ewgs3M%7EuxzMBTgxspSmGKsSc1PFYjqQZycxqv6B9y71qz7J-1RSGEiyHkfbPStBggyBRJVfKawZty0oqc5T1tEqTK9Ny47hTERiRJHEYZugixEwYvyHQuOZwFYcpDo5BMlzscJ9omwlpBA9ruw__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-09-14 04:19:31--  https://cas-bridge.xethub.hf.co/xet-bridge-us/68abccbf1935e46075b39df2/4be6804169c3353c147da4206c3982c1073abe8ac17f729a2a4c9126a8471e38?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250914%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250914T041931Z&X-Amz-Expires=3600&X-Amz-Signature=34291451127dd49a234bbe1cf841cce05475acaabeac0fbbc65cd7da3c874157&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&x-id=GetObject&Expires=1757827171&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NzgyNzE3MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OGFiY2NiZjE5MzVlNDYwNzViMzlkZjIvNGJlNjgwNDE2OWMzMzUzYzE0N2RhNDIwNmMzOTgyYzEwNzNhYmU4YWMxN2Y3MjlhMmE0YzkxMjZhODQ3MWUzOCoifV19&Signature=JYIRwDQZ49haJARFreNe%7EJ1Lx1BIUzOKy5plBHrt8Zd-1ITXhADJwvgJtn4vhSNp6fgIhGkPg2MLnsqImvrWhRkOTBvcBj3dDQP7mzc3Oh%7ElMlo56UmLB4BRC14Wxt75CwhCVOjclCv8J9vqec%7Er52xxefv-xxILboNIKQgJGHxEJBMbCpa%7EcttR4Z2-r%7E5GtI31ewgs3M%7EuxzMBTgxspSmGKsSc1PFYjqQZycxqv6B9y71qz7J-1RSGEiyHkfbPStBggyBRJVfKawZty0oqc5T1tEqTK9Ny47hTERiRJHEYZugixEwYvyHQuOZwFYcpDo5BMlzscJ9omwlpBA9ruw__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.238.243.70, 18.238.243.52, 18.238.243.30, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.238.243.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1261942732 (1.2G)\n",
            "Saving to: ‘model.safetensors’\n",
            "\n",
            "model.safetensors   100%[===================>]   1.17G  54.4MB/s    in 22s     \n",
            "\n",
            "2025-09-14 04:19:53 (54.4 MB/s) - ‘model.safetensors’ saved [1261942732/1261942732]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P0lH0RHGc_98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BntS3Q9pc_7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VkyfUy8-c_4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ComfyUI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b19b498-0485-41a2-d219-76ee9ba59bbc",
        "id": "trMdmthXdAi6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, threading, time, sys\n",
        "\n",
        "def run_comfy():\n",
        "    cmd = [\"python\", \"main.py\", \"--listen\", \"0.0.0.0\", \"--port\", \"8188\"]\n",
        "    p = subprocess.Popen(cmd, cwd=\"/content/ComfyUI\", stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in p.stdout:\n",
        "        sys.stdout.write(line)\n",
        "\n",
        "threading.Thread(target=run_comfy, daemon=True).start()\n",
        "time.sleep(8)  # ندي وقت كافي لبدء السيرفر\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88f9a65e-220c-4eb5-a188-12387a568e69",
        "id": "h4F7oFLEdAi3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n",
            "Python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.59\n",
            "ComfyUI frontend version: 1.26.11\n",
            "[Prompt Server] web root: /usr/local/lib/python3.12/dist-packages/comfyui_frontend_package/static\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n",
        "\n"
      ],
      "metadata": {
        "id": "A5tI4aiAdAi5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/cloudflared tunnel --url http://127.0.0.1:8188 --no-autoupdate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00644b35-ce2e-48b6-ac77-cf2e0b7afd25",
        "id": "wfV1u413dAi7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-09-14T04:21:27Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-09-14T04:21:27Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m |  https://achievements-shaft-dietary-entrance.trycloudflare.com                             |\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.8.1 (Checksum a66353004197ee4c1fcb68549203824882bba62378ad4d00d234bdb8251f1114)\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://127.0.0.1:8188]\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 83c0321e-e8af-4b29-b555-fdb0a259fe75\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-09-14T04:21:31Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63\n",
            "2025/09/14 04:21:31 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-09-14T04:21:32Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0mfb0f03da-08d5-4e05-a868-f9844c79b434 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63 \u001b[36mlocation=\u001b[0mams17 \u001b[36mprotocol=\u001b[0mquic\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Custom validation failed for node: audio - Invalid audio file: input_wan2.2_s2v.wav\n",
            "* VAELoader 63:\n",
            "  - Value not in list: vae_name: 'Qwen2.1\\Wan2.1_VAE.safetensors' not in ['wan_2.1_vae.safetensors', 'pixel_space']\n",
            "* LoadImage 52:\n",
            "  - Custom validation failed for node: image - Invalid image file: flux_dev_example.png\n",
            "* AudioEncoderLoader 57:\n",
            "  - Value not in list: audio_encoder_name: 'wav2vec2_large_english.safetensors' not in ['model.safetensors']\n",
            "* UnetLoaderGGUF 61:\n",
            "  - Value not in list: unet_name: 'Qwen 2SV\\Wan2.2-S2V-14B-Q2_K.gguf' not in ['Wan2.2-S2V-14B-Q2_K.gguf']\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Custom validation failed for node: audio - Invalid audio file: input_wan2.2_s2v.wav\n",
            "* VAELoader 63:\n",
            "  - Value not in list: vae_name: 'Qwen2.1\\Wan2.1_VAE.safetensors' not in ['wan_2.1_vae.safetensors', 'pixel_space']\n",
            "* AudioEncoderLoader 57:\n",
            "  - Value not in list: audio_encoder_name: 'wav2vec2_large_english.safetensors' not in ['model.safetensors']\n",
            "* UnetLoaderGGUF 61:\n",
            "  - Value not in list: unet_name: 'Qwen 2SV\\Wan2.2-S2V-14B-Q2_K.gguf' not in ['Wan2.2-S2V-14B-Q2_K.gguf']\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Custom validation failed for node: audio - Invalid audio file: input_wan2.2_s2v.wav\n",
            "* AudioEncoderLoader 57:\n",
            "  - Value not in list: audio_encoder_name: 'wav2vec2_large_english.safetensors' not in ['model.safetensors']\n",
            "* UnetLoaderGGUF 61:\n",
            "  - Value not in list: unet_name: 'Qwen 2SV\\Wan2.2-S2V-14B-Q2_K.gguf' not in ['Wan2.2-S2V-14B-Q2_K.gguf']\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Exception when validating inner node: LoadAudio.VALIDATE_INPUTS() missing 1 required positional argument: 'audio'\n",
            "* AudioEncoderLoader 57:\n",
            "  - Value not in list: audio_encoder_name: 'wav2vec2_large_english.safetensors' not in ['model.safetensors']\n",
            "* UnetLoaderGGUF 61:\n",
            "  - Value not in list: unet_name: 'Qwen 2SV\\Wan2.2-S2V-14B-Q2_K.gguf' not in ['Wan2.2-S2V-14B-Q2_K.gguf']\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Exception when validating inner node: LoadAudio.VALIDATE_INPUTS() missing 1 required positional argument: 'audio'\n",
            "* UnetLoaderGGUF 61:\n",
            "  - Value not in list: unet_name: 'Qwen 2SV\\Wan2.2-S2V-14B-Q2_K.gguf' not in ['Wan2.2-S2V-14B-Q2_K.gguf']\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* LoadAudio 58:\n",
            "  - Exception when validating inner node: LoadAudio.VALIDATE_INPUTS() missing 1 required positional argument: 'audio'\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 28:\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "\u001b[90m2025-09-14T04:29:53Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 2225 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://127.0.0.1:8188\n",
            "\u001b[90m2025-09-14T04:29:53Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 2225 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://achievements-shaft-dietary-entrance.trycloudflare.com/api/view?filename=happy-birthday-music-box(chosic.com).mp3&type=input&subfolder=&rand=0.21296524180075316 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63 \u001b[36mtype=\u001b[0mhttp\n",
            "got prompt\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "Using pytorch attention in VAE\n",
            "Using pytorch attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.float16\n",
            "Requested to load Wav2Vec2Model\n",
            "loaded completely 13752.925 617.64794921875 True\n",
            "got prompt\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "!!! Exception during processing !!! Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 496, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 315, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 289, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 277, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 228, in load_clip\n",
            "    return (self.load_patcher([clip_path], clip_type, self.load_data([clip_path])),)\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 208, in load_data\n",
            "    raise NotImplementedError(f\"Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\\n({p})\")\n",
            "NotImplementedError: Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "\n",
            "Prompt executed in 3.20 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "!!! Exception during processing !!! Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 496, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 315, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 289, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 277, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 228, in load_clip\n",
            "    return (self.load_patcher([clip_path], clip_type, self.load_data([clip_path])),)\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 208, in load_data\n",
            "    raise NotImplementedError(f\"Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\\n({p})\")\n",
            "NotImplementedError: Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "\n",
            "Prompt executed in 0.03 seconds\n",
            "!!! Exception during processing !!! Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 496, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 315, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 289, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 277, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 228, in load_clip\n",
            "    return (self.load_patcher([clip_path], clip_type, self.load_data([clip_path])),)\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 208, in load_data\n",
            "    raise NotImplementedError(f\"Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\\n({p})\")\n",
            "NotImplementedError: Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "\n",
            "Prompt executed in 0.03 seconds\n",
            "\n",
            "Stopped server\n",
            "FantasyPortrait nodes not available due to error in importing them: No module named 'onnx'\n",
            "\u001b[90m2025-09-14T04:33:33Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ComfyUI/models/clip\n",
        "!aria2c -x 16 -s 16 -o \"clip-vit-l14-q4_k_m.gguf\" \\\n",
        "\"https://huggingface.co/city96/clip-vit-l14-gguf/resolve/main/clip-vit-l14-q4_k_m.gguf?download=true\"\n"
      ],
      "metadata": {
        "id": "lWCh6k8sf_mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ComfyUI/models/clip\n",
        "!wget https://openaipublic.azureedge.net/clip/models/3035c92b350959924f9f00213499208652fc7ea050643e8b385c2dac08641f02/ViT-L-14-336px.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDY-R-ORguqN",
        "outputId": "82fd2707-35a5-417b-a8ba-54b08f8a20a0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI/models/clip\n",
            "--2025-09-14 04:37:11--  https://openaipublic.azureedge.net/clip/models/3035c92b350959924f9f00213499208652fc7ea050643e8b385c2dac08641f02/ViT-L-14-336px.pt\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.253.67, 2620:1ec:29:1::67\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.253.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 934088680 (891M) [application/octet-stream]\n",
            "Saving to: ‘ViT-L-14-336px.pt’\n",
            "\n",
            "ViT-L-14-336px.pt   100%[===================>] 890.82M   135MB/s    in 9.0s    \n",
            "\n",
            "2025-09-14 04:37:20 (99.3 MB/s) - ‘ViT-L-14-336px.pt’ saved [934088680/934088680]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JiJTz4DSg0Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j8YUlXi0g6Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G71Sgmkyg6SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NbXNwHRxg6Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yttXwvMBg6NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ComfyUI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445b8227-4e23-49cb-f4df-273c5fc810c4",
        "id": "keQ7MsSsg63C"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, threading, time, sys\n",
        "\n",
        "def run_comfy():\n",
        "    cmd = [\"python\", \"main.py\", \"--listen\", \"0.0.0.0\", \"--port\", \"8188\"]\n",
        "    p = subprocess.Popen(cmd, cwd=\"/content/ComfyUI\", stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in p.stdout:\n",
        "        sys.stdout.write(line)\n",
        "\n",
        "threading.Thread(target=run_comfy, daemon=True).start()\n",
        "time.sleep(8)  # ندي وقت كافي لبدء السيرفر\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e37d8ac-6c0a-4924-a8dd-3794be0f3f77",
        "id": "Pwo7qotKg63E"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n",
            "Python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.59\n",
            "ComfyUI frontend version: 1.26.11\n",
            "[Prompt Server] web root: /usr/local/lib/python3.12/dist-packages/comfyui_frontend_package/static\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n",
        "\n"
      ],
      "metadata": {
        "id": "wRoNxZkIg63F"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/cloudflared tunnel --url http://127.0.0.1:8188 --no-autoupdate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409ff022-f20e-4590-beb8-9fa0cfcb4ec1",
        "id": "5cqZ-gvZg63G"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-09-14T04:38:23Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-09-14T04:38:23Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m |  https://please-allen-ds-cleaning.trycloudflare.com                                        |\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.8.1 (Checksum a66353004197ee4c1fcb68549203824882bba62378ad4d00d234bdb8251f1114)\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://127.0.0.1:8188]\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 2391796e-7fce-4ed2-83c0-bd239a70a6b9\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.47\n",
            "2025/09/14 04:38:28 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-09-14T04:38:28Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0mddafdf77-2f51-4fa1-8082-62493efd64e6 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.47 \u001b[36mlocation=\u001b[0mams08 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-09-14T04:43:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 2121 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://127.0.0.1:8188\n",
            "\u001b[90m2025-09-14T04:43:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 2121 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://please-allen-ds-cleaning.trycloudflare.com/api/view?filename=happy-birthday-music-box(chosic.com).mp3&type=input&subfolder=&rand=0.6647587033422917 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.47 \u001b[36mtype=\u001b[0mhttp\n",
            "got prompt\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "Using pytorch attention in VAE\n",
            "Using pytorch attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.float16\n",
            "Requested to load Wav2Vec2Model\n",
            "loaded completely 13752.925 617.64794921875 True\n",
            "!!! Exception during processing !!! Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 496, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 315, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 289, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 277, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 228, in load_clip\n",
            "    return (self.load_patcher([clip_path], clip_type, self.load_data([clip_path])),)\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 208, in load_data\n",
            "    raise NotImplementedError(f\"Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\\n({p})\")\n",
            "NotImplementedError: Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "\n",
            "Prompt executed in 1.90 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "/usr/local/lib/python3.12/dist-packages/torch/serialization.py:1493: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
            "  warnings.warn(\n",
            "!!! Exception during processing !!! Cannot use ``weights_only=True`` with TorchScript archives passed to ``torch.load``. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 496, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 315, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 289, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 277, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 228, in load_clip\n",
            "    return (self.load_patcher([clip_path], clip_type, self.load_data([clip_path])),)\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 206, in load_data\n",
            "    sd = comfy.utils.load_torch_file(p, safe_load=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 82, in load_torch_file\n",
            "    pl_sd = torch.load(ckpt, map_location=device, weights_only=True, **torch_args)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1500, in load\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Cannot use ``weights_only=True`` with TorchScript archives passed to ``torch.load``. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "!!! Exception during processing !!! Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 496, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 315, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 289, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 277, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 228, in load_clip\n",
            "    return (self.load_patcher([clip_path], clip_type, self.load_data([clip_path])),)\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 208, in load_data\n",
            "    raise NotImplementedError(f\"Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\\n({p})\")\n",
            "NotImplementedError: Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "!!! Exception during processing !!! Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 496, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 315, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 289, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 277, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 228, in load_clip\n",
            "    return (self.load_patcher([clip_path], clip_type, self.load_data([clip_path])),)\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 208, in load_data\n",
            "    raise NotImplementedError(f\"Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\\n({p})\")\n",
            "NotImplementedError: Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "!!! Exception during processing !!! Cannot use ``weights_only=True`` with TorchScript archives passed to ``torch.load``. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 496, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 315, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 289, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 277, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 228, in load_clip\n",
            "    return (self.load_patcher([clip_path], clip_type, self.load_data([clip_path])),)\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 206, in load_data\n",
            "    sd = comfy.utils.load_torch_file(p, safe_load=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 82, in load_torch_file\n",
            "    pl_sd = torch.load(ckpt, map_location=device, weights_only=True, **torch_args)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1500, in load\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Cannot use ``weights_only=True`` with TorchScript archives passed to ``torch.load``. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\n",
            "Prompt executed in 0.01 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "!!! Exception during processing !!! Cannot use ``weights_only=True`` with TorchScript archives passed to ``torch.load``. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 496, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 315, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 289, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 277, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 228, in load_clip\n",
            "    return (self.load_patcher([clip_path], clip_type, self.load_data([clip_path])),)\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 206, in load_data\n",
            "    sd = comfy.utils.load_torch_file(p, safe_load=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 82, in load_torch_file\n",
            "    pl_sd = torch.load(ckpt, map_location=device, weights_only=True, **torch_args)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1500, in load\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Cannot use ``weights_only=True`` with TorchScript archives passed to ``torch.load``. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\n",
            "Prompt executed in 0.01 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 68:\n",
            "* ImageResize 70:\n",
            "  - Required input is missing: pixels\n",
            "Output will be ignored\n",
            "!!! Exception during processing !!! Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 496, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 315, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 289, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 277, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 228, in load_clip\n",
            "    return (self.load_patcher([clip_path], clip_type, self.load_data([clip_path])),)\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-GGUF/nodes.py\", line 208, in load_data\n",
            "    raise NotImplementedError(f\"Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\\n({p})\")\n",
            "NotImplementedError: Mixing scaled FP8 with GGUF is not supported! Use regular CLIP loader or switch model(s)\n",
            "(/content/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n",
            "\n",
            "Prompt executed in 0.04 seconds\n",
            "\n",
            "Stopped server\n",
            "FantasyPortrait nodes not available due to error in importing them: No module named 'onnx'\n",
            "\u001b[90m2025-09-14T04:48:24Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ComfyUI/models/text_encoders\n",
        "!wget https://huggingface.co/city96/umt5-xxl-encoder-gguf/resolve/main/umt5-xxl-encoder-Q3_K_S.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq9Rx_5ijZf2",
        "outputId": "8549b105-bfed-4684-eddb-196ee8411aca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI/models/text_encoders\n",
            "--2025-09-14 04:48:43--  https://huggingface.co/city96/umt5-xxl-encoder-gguf/resolve/main/umt5-xxl-encoder-Q3_K_S.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.49, 18.239.50.103, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/e8/98/e8984ed8e83768f7484dd9488494adfcbbac2f1a442fbc9774c87625d1cf7464/f64f8d6dc4d8a24276df69d0ccea789aae686f7417950a41e6568c30cb478a5c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27umt5-xxl-encoder-Q3_K_S.gguf%3B+filename%3D%22umt5-xxl-encoder-Q3_K_S.gguf%22%3B&Expires=1757828923&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NzgyODkyM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U4Lzk4L2U4OTg0ZWQ4ZTgzNzY4Zjc0ODRkZDk0ODg0OTRhZGZjYmJhYzJmMWE0NDJmYmM5Nzc0Yzg3NjI1ZDFjZjc0NjQvZjY0ZjhkNmRjNGQ4YTI0Mjc2ZGY2OWQwY2NlYTc4OWFhZTY4NmY3NDE3OTUwYTQxZTY1NjhjMzBjYjQ3OGE1Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=CfWBccBYnPcWgRGS4ryG4HIUc1qgkJ5rzqgF0m14WXNlVQd-ZPeJkX2zHlOJy5vLvHVpA8%7E81h6dtDtnJFABKhpqfD3aFmentRYGRNFApJpSV7to5HQ9c0OtE2c70%7EVTOz-BtQOKFzfEsBP-H1bK8RAA%7EEugK7tuvuW6TCstFgekisJN7V-qt21UHVN39r%7EHD2bIft2tI%7E2hDe5uFz%7Es3x3S7V0rQOK-M3-4DsZILHQslGlr78yBNj7U5e3DJoRelLVXWxH6L0r2Lj2iPDTR80XNyW0JAeeisU4ukBDe2ynHp0xAVpwPYCZvqf44Wo5j3fo44RSbIU3cG%7EhcDYzu3w__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-09-14 04:48:43--  https://cdn-lfs-us-1.hf.co/repos/e8/98/e8984ed8e83768f7484dd9488494adfcbbac2f1a442fbc9774c87625d1cf7464/f64f8d6dc4d8a24276df69d0ccea789aae686f7417950a41e6568c30cb478a5c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27umt5-xxl-encoder-Q3_K_S.gguf%3B+filename%3D%22umt5-xxl-encoder-Q3_K_S.gguf%22%3B&Expires=1757828923&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NzgyODkyM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U4Lzk4L2U4OTg0ZWQ4ZTgzNzY4Zjc0ODRkZDk0ODg0OTRhZGZjYmJhYzJmMWE0NDJmYmM5Nzc0Yzg3NjI1ZDFjZjc0NjQvZjY0ZjhkNmRjNGQ4YTI0Mjc2ZGY2OWQwY2NlYTc4OWFhZTY4NmY3NDE3OTUwYTQxZTY1NjhjMzBjYjQ3OGE1Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=CfWBccBYnPcWgRGS4ryG4HIUc1qgkJ5rzqgF0m14WXNlVQd-ZPeJkX2zHlOJy5vLvHVpA8%7E81h6dtDtnJFABKhpqfD3aFmentRYGRNFApJpSV7to5HQ9c0OtE2c70%7EVTOz-BtQOKFzfEsBP-H1bK8RAA%7EEugK7tuvuW6TCstFgekisJN7V-qt21UHVN39r%7EHD2bIft2tI%7E2hDe5uFz%7Es3x3S7V0rQOK-M3-4DsZILHQslGlr78yBNj7U5e3DJoRelLVXWxH6L0r2Lj2iPDTR80XNyW0JAeeisU4ukBDe2ynHp0xAVpwPYCZvqf44Wo5j3fo44RSbIU3cG%7EhcDYzu3w__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.239.36.72, 18.239.36.68, 18.239.36.52, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.239.36.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2858489696 (2.7G) [binary/octet-stream]\n",
            "Saving to: ‘umt5-xxl-encoder-Q3_K_S.gguf’\n",
            "\n",
            "umt5-xxl-encoder-Q3 100%[===================>]   2.66G   203MB/s    in 22s     \n",
            "\n",
            "2025-09-14 04:49:05 (126 MB/s) - ‘umt5-xxl-encoder-Q3_K_S.gguf’ saved [2858489696/2858489696]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PmDL3DiajdF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "brdJHN3aji2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wEC3nX06ji5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQByBOEtji8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tykzzR1Lji-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ComfyUI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee1a38e-3855-4a24-8458-79c1f0cc5b50",
        "id": "rhxKdBqAjjQw"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, threading, time, sys\n",
        "\n",
        "def run_comfy():\n",
        "    cmd = [\"python\", \"main.py\", \"--listen\", \"0.0.0.0\", \"--port\", \"8188\"]\n",
        "    p = subprocess.Popen(cmd, cwd=\"/content/ComfyUI\", stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in p.stdout:\n",
        "        sys.stdout.write(line)\n",
        "\n",
        "threading.Thread(target=run_comfy, daemon=True).start()\n",
        "time.sleep(8)  # ندي وقت كافي لبدء السيرفر\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fecff488-0f3c-4d79-8d44-ddbd5db2bba0",
        "id": "9XDVFy9sjjQx"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n",
            "Python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.59\n",
            "ComfyUI frontend version: 1.26.11\n",
            "[Prompt Server] web root: /usr/local/lib/python3.12/dist-packages/comfyui_frontend_package/static\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n",
        "\n"
      ],
      "metadata": {
        "id": "AuPbJr41jjQy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/cloudflared tunnel --url http://127.0.0.1:8188 --no-autoupdate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f9b3d4-cb41-4597-dce4-ee5260aa01f6",
        "id": "7W9zOZNdjjQz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-09-14T05:02:11Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-09-14T05:02:11Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "ComfyUI-GGUF: Allowing full torch compile\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/image-resize-comfyui\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Custom-Scripts\n",
            "   8.1 seconds: /content/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper\n",
            "\n",
            "Context impl SQLiteImpl.\n",
            "Will assume non-transactional DDL.\n",
            "No target revision found.\n",
            "Starting server\n",
            "\n",
            "To see the GUI go to: http://0.0.0.0:8188\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m |  https://christopher-board-thanks-made.trycloudflare.com                                   |\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.8.1 (Checksum a66353004197ee4c1fcb68549203824882bba62378ad4d00d234bdb8251f1114)\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://127.0.0.1:8188]\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 22cd9092-1486-4dc9-876c-d91d97445b67\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.227\n",
            "2025/09/14 05:02:15 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-09-14T05:02:15Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0mebaf5689-930a-42d5-a503-ff7c04d375a5 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.227 \u001b[36mlocation=\u001b[0mams07 \u001b[36mprotocol=\u001b[0mquic\n"
          ]
        }
      ]
    }
  ]
}